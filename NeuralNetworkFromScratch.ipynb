{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Autor: Juan Sebastián Vargas\n",
        "\n",
        "Resolver la compuerta XOR con una red Neuronal"
      ],
      "metadata": {
        "id": "X3XAE2_BRR6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://www.niser.ac.in/~smishra/teach/cs460/2020/lectures/lec19/Perceptron.jpg)"
      ],
      "metadata": {
        "id": "r_A3uXE8RaVN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8RfnzFdG2dL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_circles\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationFunction():\n",
        "  def __init__(self,act_f):\n",
        "    if(act_f==\"sig\"):\n",
        "      self.act_f= (lambda x: 1/(1+np.e**(-x))), (lambda x: x*(1-x))\n",
        "    elif (act_f==\"RELU\"):\n",
        "      self.act_f= (lambda x: np.maximum(0,x)), (lambda x: (x > 0) * 1) "
      ],
      "metadata": {
        "id": "RsTHzm-bIoLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CostFunction():\n",
        "  def __init__(self,cost_f):\n",
        "    if(cost_f==\"BCE\"):\n",
        "      self.cost_f= (lambda a,y: y*np.log(a)+(1-y)*np.log(1-a)), (lambda a,y: (-y/a)+((1-y)/(1-a))  )\n",
        "    elif(cost_f==\"SE\"):\n",
        "      self.cost_f= (lambda a,y: np.mean((y-a)**2)), (lambda a,y:(a-y))"
      ],
      "metadata": {
        "id": "IMJww4AaIrDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralLayer():\n",
        "  def __init__(self,n_previous_neurons,n_neurons,act_f):\n",
        "    self.n_previous_neurons=n_previous_neurons\n",
        "    self.n_neurons=n_neurons\n",
        "    self.act_f=act_f\n",
        "    self.b= np.random.rand(n_neurons)\n",
        "    self.w= np.random.rand(n_previous_neurons,n_neurons)\n",
        "    self.z= np.zeros(n_neurons)\n",
        "    self.a= np.zeros(n_neurons)\n",
        "    self.act_f= ActivationFunction(act_f).act_f\n",
        "    print(self.b)\n",
        "    print(self.w)\n",
        "    print(self.a)\n",
        "\n",
        "  def updateActivationResult(self,input, isLast, epoch_index):\n",
        "      #print(\"INPUT: \",input)\n",
        "      #print(\"WT: \",self.w.T)\n",
        "      #print(\"B: \",self.b)\n",
        "      self.z= input @ self.w  + self.b\n",
        "      print(\"Z VALUES: \", self.z)\n",
        "      self.a= self.act_f[0](self.z)\n",
        "      print(\"A VALUES: \", self.a)\n",
        "      if(isLast):\n",
        "        print(\"Predicción: \", self.a)\n"
      ],
      "metadata": {
        "id": "2wkek_BdIsXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork():\n",
        "  def __init__(self, topography, activ_f, cost_f):\n",
        "    self.topography=topography\n",
        "    self.activ_f=activ_f\n",
        "    self.cost_f=cost_f\n",
        "    self._layers=[]\n",
        "    for i in range(1,len(self.topography)):\n",
        "      self._layers.append(NeuralLayer(self.topography[i-1],self.topography[i],self.activ_f))\n",
        "    print(\"LAYER SIZE: \",len(self._layers))  \n",
        "\n",
        "  def train(self,X,Y,lr,epoch):\n",
        "      y_inflated= Y[:,np.newaxis]\n",
        "      for e in range(0,epoch):\n",
        "          #print(x_i[0],x_i[1], y_i)\n",
        "          #print(\".................FOWARD................\")\n",
        "          self.__feedFoward(X,y_inflated,e)\n",
        "          #print(\".................BACKPROPAGATION................\")\n",
        "          self.__backPropagation(X,y_inflated,lr)\n",
        "          #print(\"\\n\\n----NEW X VALUES-------\\n\\n\")\n",
        "\n",
        "  def __feedFoward(self,x,y,epoch_index):\n",
        "    self._layers[0].updateActivationResult(x,False,0)\n",
        "    for i in range(1,len(self._layers)):\n",
        "      #print(\"LAYER: ------- \",i)\n",
        "      if(i==len(self._layers)-1):\n",
        "        self._layers[i].updateActivationResult(self._layers[i-1].a,True,epoch_index)\n",
        "      else:\n",
        "        self._layers[i].updateActivationResult(self._layers[i-1].a,False,epoch_index)\n",
        "\n",
        "\n",
        "  def __printNeuralNetwork(self):    \n",
        "    print(\"*****************************NN****************\")  \n",
        "    for i in range(0,len(self._layers)):\n",
        "      print(\"LAYER: ------- \",i)\n",
        "      print(\"Z: \", self._layers[i].z)\n",
        "      print(\"A: \", self._layers[i].a)\n",
        "      print(\"-----------------\")\n",
        "    print(\"*****************************NN****************\")  \n",
        "\n",
        "\n",
        "\n",
        "  def __backPropagation(self,x,y,lr):\n",
        "    #print(\"Y: \",y)\n",
        "    #print(\"Activation in last layer: \",self._layers[-1].a, len(self._layers[-1].a))\n",
        "    #print(\"Costo: \",CostFunction(\"SE\").cost_f[0](self._layers[-1].a,y))\n",
        "    #print(\"dC_da: \",dC_da)\n",
        "    delta=0\n",
        "    for i in reversed(range(0,len(self._layers))):\n",
        "      #print(\"LAYER #: \",i)\n",
        "      if(i==len(self._layers)-1):\n",
        "        #print(\"LAST LAYER: \")\n",
        "        #print(\"COST: \",CostFunction(\"SE\").cost_f[0](self._layers[-1].a,y))\n",
        "        #print(\"D_COST: \",CostFunction(\"BCE\").cost_f[1](self._layers[-1].a,y))\n",
        "        #print(\"ACTIVATION LAST LAYER: \",self._layers[-1].a)\n",
        "        #print(\"W LAST LAYER: \",self._layers[-1].w)\n",
        "        #print(\"B LAST LAYER: \",self._layers[-1].b)\n",
        "        #print(\"Z LAST LAYER: \",self._layers[-1].z)\n",
        "        #print(\"Z LAST LAYER: \",self._layers[-1].z)\n",
        "        dC_da= CostFunction(self.cost_f).cost_f[1](self._layers[-1].a,y)\n",
        "\n",
        "\n",
        "        #print(\"dC_da\",dC_da.shape)\n",
        "\n",
        "        da_dZ= self._layers[i].act_f[1](self._layers[-1].a) ### <<----- OJO MIRAR 1\n",
        "        \n",
        "      \n",
        "        #print(\"da_dz\",da_dZ.shape)\n",
        "\n",
        "        delta=dC_da*da_dZ\n",
        "\n",
        "        #print(\"I: \",i)\n",
        "        #print(\"I-1: \",i-1)\n",
        "        dZ_dW= self._layers[i-1].a \n",
        "\n",
        "        #print(\"Delta: \", delta.shape)\n",
        "\n",
        "        gW= dZ_dW.T @ delta  ##Gradiente en W\n",
        "\n",
        "        gb= np.mean(delta,axis=0, keepdims=True) ##Gradiente en b\n",
        "\n",
        "        #print(\"W: \",self._layers[-1].w.shape)\n",
        "        #print(\"FIRST LAYER gW\" ,gW.shape)\n",
        "        #print(\"gb\" ,gb.shape)\n",
        "\n",
        "\n",
        "        self._layers[-1].b= self._layers[-1].b - lr*(gb)\n",
        "        self._layers[-1].w= self._layers[-1].w - lr*(gW)\n",
        "\n",
        "      \n",
        "\n",
        "      else:\n",
        "        #print(\"OTHER LAYER, #: \",i)\n",
        "      \n",
        "\n",
        "        da_dZ= self._layers[i].act_f[1](self._layers[i].a) ### <<----- OJO MIRAR 2\n",
        "\n",
        "        #print(\"Delta: \", delta.shape)\n",
        "        #print(self._layers[i+1].w.shape)\n",
        "        #print(da_dZ.shape)\n",
        "\n",
        "        delta= (delta @ self._layers[i+1].w.T ) * da_dZ\n",
        "\n",
        "        #print(\"New Delta: \", delta.shape)\n",
        "\n",
        "        #print(\"I: \",i)\n",
        "        #print(\"I-1: \",i-1)\n",
        "\n",
        "        if(i==0):\n",
        "          dZ_dW= x\n",
        "        else:\n",
        "          dZ_dW= self._layers[i-1].a   \n",
        "\n",
        "        #print(\"dZ_dW: \", dZ_dW.shape)\n",
        "\n",
        "        gW= dZ_dW.T @ delta  ##Gradiente en W\n",
        "\n",
        "        #print(gW.shape)\n",
        "\n",
        "\n",
        "        gb= np.mean(delta,axis=0, keepdims=True) ##Gradiente en b\n",
        "\n",
        "        self._layers[i].b= self._layers[i].b - lr*(gb)\n",
        "        self._layers[i].w= self._layers[i].w - lr*(gW)\n",
        "\n",
        "        \n",
        "        \n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "41-OSazNIwyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.array([\n",
        "    [1,1],\n",
        "    [1,0],\n",
        "    [0,0],\n",
        "    [0,1],\n",
        "])\n",
        "y_train= np.array([0,1,0,1])"
      ],
      "metadata": {
        "id": "PBApSw43G-Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=NeuralNetwork([2,2,1],\"RELU\",\"BCE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwRJBhzEIxrr",
        "outputId": "5e897fb7-dcae-4064-e442-3b412103dd47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.57107471 0.78168651]\n",
            "[[0.11666017 0.64091598]\n",
            " [0.4575166  0.05526268]]\n",
            "[0. 0.]\n",
            "[0.20343467]\n",
            "[[0.20348811]\n",
            " [0.85292141]]\n",
            "[0.]\n",
            "LAYER SIZE:  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(x_train,y_train,0.00001,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYgfgQXDM7iz",
        "outputId": "19a12628-bb0e-47ef-c2af-05c45a76e7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z VALUES:  [[1.14525148 1.47786517]\n",
            " [0.68773488 1.42260249]\n",
            " [0.57107471 0.78168651]\n",
            " [1.02859131 0.83694918]]\n",
            "A VALUES:  [[1.14525148 1.47786517]\n",
            " [0.68773488 1.42260249]\n",
            " [0.57107471 0.78168651]\n",
            " [1.02859131 0.83694918]]\n",
            "Z VALUES:  [[1.69698258]\n",
            " [1.55674867]\n",
            " [0.98635875]\n",
            " [1.12659266]]\n",
            "A VALUES:  [[1.69698258]\n",
            " [1.55674867]\n",
            " [0.98635875]\n",
            " [1.12659266]]\n",
            "Predicción:  [[1.69698258]\n",
            " [1.55674867]\n",
            " [0.98635875]\n",
            " [1.12659266]]\n"
          ]
        }
      ]
    }
  ]
}